""" Trainer object defined for the IDGAN system. Trains the model either for a predefined maximum number of training
epochs or until some early stopping condition is met. Samples sequences generated by the generator/ translator SAE
during validation steps for a continuous, subjective evaluation of model performance. A note regarding the employed
nomenclature: 'encoder labels', here, refers to SAE labels, i.e. SAE inputs shifted by one step and sentence-final <EOS>
as opposed to the sentence-initial <GO>, as is the case for SAE inputs. """

import os
import time
import pickle
import logging
import numpy as np
import tensorflow as tf

from autoencoder.src.codebase.batching import DataServer
from shared.util import save_model


class IDGANTrainer(object):
    """ Trains the model on the specified training set, using a validation set to monitor model's capacity for
    generalization and to prevent over-fitting via early stopping. """
    
    def __init__(self, vocab, opt, model, session, source_train_data, source_valid_data, target_train_data,
                 target_valid_data, test_opt=None, interface=None, verbose=True):
        # Declare arguments
        self.vocab = vocab
        self.opt = opt
        self.model = model
        self.session = session
        # Designate target domain (low-ID) data
        self.source_train_data = source_train_data
        self.source_valid_data = source_valid_data
        # Designate source domain (high-ID) data
        self.target_train_data = target_train_data
        self.target_valid_data = target_valid_data
        # Components tasked with sampling IDGAN's output at validation time
        self.test_opt = test_opt
        self.interface = interface
        # Reporting style toggle
        self.verbose = verbose
        # Archive various values for post-hoc visualization of training trajectories  
        self.train_pickle_dict = {
            'gen_train_losses': list(),
            'gen_grad_norms': list(),
            'disc_train_losses': list(),
            'disc_grad_norms': list(),
            'train_id_reduction_scores': list(),
            'gen_adv_losses': list(),
            'gen_rec_losses': list()
        }
        self.valid_pickle_dict = {
            'gen_valid_losses': list(),
            'id_reduction_scores': list(),
            'disc_valid_losses': list(),
            'gen_adv_losses': list(),
            'gen_rec_losses': list()
        }
        self.train_pickle_archive = os.path.join(self.opt.out_dir, 'train_pickle_archive.pkl')
        self.valid_pickle_archive = os.path.join(self.opt.out_dir, 'valid_pickle_archive.pkl')

        # Declare initial scheduled sampling bias
        self.sampling_bias = 1.0
        # Declare initial learning rates
        self.current_gen_lr = self.opt.gen_lr
        self.current_disc_lr = self.opt.disc_lr

        # Initialize global step variables (gen == generator, disc == discriminator)
        self.total_train_global_step = 0
        self.total_valid_global_step = 0
        self.gen_train_global_step = 0
        self.gen_valid_global_step = 0
        self.disc_train_global_step = 0
        self.disc_valid_global_step = 0

        # Track validation epoch with highest ID-reduction
        self.id_reduction_best = 0.0
        self.id_validation_best = float('inf')
        self.id_training_best = float('inf')
        # Track best validation epoch overall
        self.all_validation_best = float('inf')
        self.all_training_best = float('inf')
        self.stagnant_epochs = 0
        self.final_epoch = 0
        self.best_epoch = 0
        self.stopped_early = False
        self.start_time = None

        # Define a single GAN training step
        self.gen_iterations = self.opt.gen_steps
        self.disc_iterations = self.opt.disc_steps
        # For WGAN(-GP), update the critic more frequently than the generator
        if self.opt.gan_type == 'WGAN' or self.opt.gan_type == 'WGANGP':
            self.disc_iterations += 4
        # Determine the number of joint updates during a single GAN step
        self.joint_iterations = min(self.gen_iterations, self.disc_iterations)

        # Initialize writer objects needed for the construction of TensorBoard summaries
        self.gen_train_writer = tf.summary.FileWriter(self.opt.log_dir + '/train', session.graph)
        self.gen_valid_writer = tf.summary.FileWriter(self.opt.log_dir + '/valid', session.graph)
        self.disc_train_writer = tf.summary.FileWriter(self.opt.log_dir + '/train', session.graph)
        self.disc_valid_writer = tf.summary.FileWriter(self.opt.log_dir + '/valid', session.graph)
        # Initialize a saver object for the creation of checkpoints
        self.model_saver = tf.train.Saver()

    def train_gan(self):
        """ Defines the primary training loop for the adversarial stage of IDGAN training. """

        def _switch_task(condition_data=None):
            """ Multi-task learning task switching function, used to alternate between the adversarial learning task and
            the reconstruction task during generator updates; switching may be conditioned on condition_data. """
            if condition_data is None:
                # 'Static' multi-task learning scenario; alternate adversarial and reconstruction updates independently
                # of current system performance
                activation = np.random.uniform(0.0, 1.0)
                threshold = 0.5
            else:
                # 'Dynamic' multi-task learning scenario; task switching is conditioned on system performance,
                # e.g. generator's adversarial loss during the validation phase
                activation = np.mean(condition_data)
                threshold = 0.5  # for generator's adversarial loss
            # Switch task by reassigning objective lambda values, effectively switching partial objectives off and on
            if activation < threshold:
                self.adv_lambda = 1.0
                self.rec_lambda = 0.0
            else:
                self.adv_lambda = 0.0
                self.rec_lambda = 1.0

        self.start_time = time.time()

        # Document current training configuration
        logging.info('=' * 10)
        logging.info('Adversarial lambda: {:f}'.format(self.opt.adv_lambda))
        logging.info('ID lambda: {:f}'.format(self.opt.id_lambda))
        logging.info('Reconstruction lambda: {:f}'.format(self.opt.rec_lambda))
        logging.info('GEN steps: {:d}'.format(self.gen_iterations))
        logging.info('DISC steps: {:d}'.format(self.disc_iterations))
        logging.info('=' * 10)

        for e in range(self.opt.num_epochs):
            # (Re-)initialize tracking variables and containers
            epoch_start = time.time()
            words_processed = 0
            gen_grad_norms = list()
            gen_train_losses = list()
            gen_adv_losses = list()
            gen_rec_losses = list()
            disc_grad_norms = list()
            disc_train_losses = list()
            train_id_reduction_scores = list()
            # (Re-)initialize the training data loaders for both ID domains at the start of each training epoch;
            # Epoch concludes once training data has been exhausted
            source_train_loader = DataServer(self.source_train_data, self.vocab, self.opt)
            target_train_loader = DataServer(self.target_train_data, self.vocab, self.opt)
            # Update the scheduled sampling bias for each epoch;
            # translator SAE decoder is more likely to receive its own output from previous time-step at later epochs
            if self.opt.schedule_sampling:
                self.sampling_bias = self.opt.scheduling_constant / (
                    self.opt.scheduling_constant + np.exp(e / self.opt.scheduling_constant))
            else:
                self.sampling_bias = 1.0
            # Decide how many mini-batches should be drawn per GAN step
            batches_drawn = max(self.gen_iterations, self.disc_iterations)

            while True:
                # (Re-)initialize mini-batch container for the current step
                step_batches = list()

                # Draw mini-batches to be used for the generator and discriminator updates
                # during a single GAN training step
                out_of_data = False
                for batch_id in range(batches_drawn):
                    try:
                        joint_batch = list()
                        joint_batch += next(source_train_loader)
                        joint_batch += next(target_train_loader)
                        step_batches.append(joint_batch)
                    except StopIteration:
                        out_of_data = True
                        break
                # Terminate epoch once training corpora are exhausted
                if out_of_data:
                    break

                # Perform joint updates
                for j_i in range(self.joint_iterations):

                    # Optionally switch between adversarial and reconstruction objectives at each generator step
                    if self.opt.multi_task == 'static':
                        _switch_task()

                    # Unpack mini-batch data
                    source_labels, source_enc_inputs, source_dec_inputs = step_batches[j_i][:3]
                    target_labels, target_enc_inputs, target_dec_inputs = step_batches[j_i][3:]
                    # Perform a single update step
                    gen_grad_norm, gen_train_loss, disc_grad_norm, disc_train_loss, train_id_reduction, \
                        partial_losses = self.joint_train_step(source_labels, source_enc_inputs, source_dec_inputs,
                                                               target_labels, target_enc_inputs, target_dec_inputs)
                    words_processed += (np.product(source_enc_inputs.shape) + np.product(source_dec_inputs.shape))
                    # Update tracked generator values
                    gen_grad_norms.append(gen_grad_norm)
                    gen_train_losses.append(gen_train_loss)
                    gen_adv_losses.append(partial_losses[0])
                    gen_rec_losses.append(partial_losses[1])
                    # Update tracked discriminator values
                    disc_grad_norms.append(disc_grad_norm)
                    disc_train_losses.append(disc_train_loss)
                    # Update ID reduction values observed during training
                    train_id_reduction_scores.append(train_id_reduction)
                    # Update global step variables
                    self.gen_train_global_step += 1
                    self.disc_train_global_step += 1

                # Perform generator-only updates
                for g_i in range(self.gen_iterations - self.joint_iterations):

                    # Optionally switch between adversarial and reconstruction objectives at each generator step
                    if self.opt.multi_task == 'static':
                        _switch_task()

                    # Unpack mini-batch data
                    source_labels, source_enc_inputs, source_dec_inputs = step_batches[g_i][:3]
                    target_labels, target_enc_inputs, target_dec_inputs = step_batches[g_i][3:]
                    # Perform a single update step
                    gen_grad_norm, gen_train_loss, train_id_reduction, partial_losses = self.gen_train_step(
                        source_labels, source_enc_inputs, source_dec_inputs,
                        target_labels, target_enc_inputs, target_dec_inputs)
                    words_processed += np.product(source_enc_inputs.shape)
                    # Update tracked generator values
                    gen_grad_norms.append(gen_grad_norm)
                    gen_train_losses.append(gen_train_loss)
                    gen_adv_losses.append(partial_losses[0])
                    gen_rec_losses.append(partial_losses[1])
                    # Update ID reduction values observed during training
                    train_id_reduction_scores.append(train_id_reduction)
                    # Update global step variable
                    self.gen_train_global_step += 1

                # Perform discriminator-only updates
                for d_i in range(self.disc_iterations - self.joint_iterations):
                    # Unpack mini-batch data
                    source_labels, source_enc_inputs, source_dec_inputs = step_batches[d_i][:3]
                    target_labels, target_enc_inputs, target_dec_inputs = step_batches[d_i][3:]
                    # Perform a single update step
                    disc_grad_norm, disc_train_loss = self.disc_train_step(source_enc_inputs, target_enc_inputs)
                    words_processed += (
                        np.product(source_enc_inputs.shape) + np.product(source_dec_inputs.shape))
                    # Update tracked discriminator values
                    disc_grad_norms.append(disc_grad_norm)
                    disc_train_losses.append(disc_train_loss)
                    # Update global step variable
                    self.disc_train_global_step += 1

                # Update GAN global step variable
                self.total_train_global_step += 1

                # Calculate training statistics for the reporting interval
                if self.total_train_global_step % self.opt.report_freq == 0 and self.total_train_global_step != 0:
                    logging.info('[TRAINING] Epoch {:d} | Global GAN step: {:d}'.format(
                        e, self.total_train_global_step))

                    # Generator statistics
                    if self.gen_iterations > 0:
                        gen_train_loss_avg = sum(gen_train_losses[-self.opt.report_freq:]) / self.opt.report_freq
                        gen_train_loss_var = np.var(gen_train_losses[-self.opt.report_freq:])
                        gen_grad_norm_avg = sum(gen_grad_norms[-self.opt.report_freq:]) / self.opt.report_freq
                        logging.info('[GEN] Global step: {:d} | Loss mean: {:.4f} | Loss var: {:.4f}'.format(
                            self.gen_train_global_step, gen_train_loss_avg, gen_train_loss_var))
                        logging.info('[GEN] Gradient norm mean: {:.4f}'.format(gen_grad_norm_avg))

                    # Discriminator statistics
                    if self.disc_iterations > 0:
                        disc_train_loss_avg = sum(disc_train_losses[-self.opt.report_freq:]) / self.opt.report_freq
                        disc_train_loss_var = np.var(disc_train_losses[-self.opt.report_freq:])
                        disc_grad_norm_avg = sum(disc_grad_norms[-self.opt.report_freq:]) / self.opt.report_freq
                        logging.info('[DISC] Global step: {:d} | Loss mean: {:.4f} | Loss var: {:.4f}'.format(
                            self.disc_train_global_step, disc_train_loss_avg, disc_train_loss_var))
                        logging.info('[DISC] Gradient norm mean: {:.4f}'.format(disc_grad_norm_avg))

            # Calculate training statistics for the full training epoch
            epoch_wps = words_processed / (time.time() - epoch_start)
            gen_epoch_train_loss_avg = 0.0
            disc_epoch_train_loss_avg = 0.0

            logging.info('[TRAINING] EPOCH {:d} CONCLUDED | AVERAGE SPEED: {:.2f} WPS'.format(e, epoch_wps))

            # Generator statistics
            if self.gen_iterations > 0:
                gen_epoch_train_loss_avg = sum(gen_train_losses) / len(gen_train_losses)
                gen_epoch_train_loss_var = np.var(gen_train_losses)
                gen_epoch_grad_norm_avg = sum(gen_grad_norms) / len(gen_grad_norms)
                logging.info('[GEN] EPOCH LOSS MEAN: {:.4f} | EPOCH LOSS VAR: {:.4f}'.format(
                    gen_epoch_train_loss_avg, gen_epoch_train_loss_var))
                logging.info('[GEN] EPOCH GRADIENT NORM MEAN: {:.4f}'.format(gen_epoch_grad_norm_avg))

            # Discriminator statistics
            if self.disc_iterations > 0:
                disc_epoch_train_loss_avg = sum(disc_train_losses) / len(disc_train_losses)
                disc_epoch_train_loss_var = np.var(disc_train_losses)
                disc_epoch_grad_norm_avg = sum(disc_grad_norms) / len(disc_grad_norms)
                logging.info('[DISC] EPOCH LOSS MEAN: {:.4f} | EPOCH LOSS VAR: {:.4f}'.format(
                    disc_epoch_train_loss_avg, disc_epoch_train_loss_var))
                logging.info('[DISC] EPOCH GRADIENT NORM MEAN: {:.4f}'.format(disc_epoch_grad_norm_avg))

            # Store training losses in one list, for convenience
            epoch_train_losses = [gen_epoch_train_loss_avg, disc_epoch_train_loss_avg]

            # Pickle tracked epoch-wise training values for subsequent access
            self.train_pickle_dict['gen_train_losses'].append(np.mean(gen_train_losses))
            self.train_pickle_dict['gen_grad_norms'].append(np.mean(gen_grad_norms))
            self.train_pickle_dict['disc_train_losses'].append(np.mean(disc_train_losses))
            self.train_pickle_dict['disc_grad_norms'].append(np.mean(disc_grad_norms))
            self.train_pickle_dict['train_id_reduction_scores'].append(np.mean(train_id_reduction_scores))
            self.train_pickle_dict['gen_adv_losses'].append(np.mean(gen_adv_losses))
            self.train_pickle_dict['gen_rec_losses'].append(np.mean(gen_rec_losses))
            with open(self.train_pickle_archive, 'wb') as in_pickle:
                pickle.dump(self.train_pickle_dict, in_pickle)

            # Perform validation steps at the end of each training epoch after the specified warm-up period
            if e >= self.opt.start_early_stopping:
                # (Re-)initialize tracking variables and containers
                gen_valid_losses = list()
                gen_adv_losses = list()
                gen_rec_losses = list()
                id_reduction_scores = list()
                disc_valid_losses = list()
                # (Re-)initialize the validation data loaders
                source_valid_loader = DataServer(self.source_valid_data, self.vocab, self.opt)
                target_valid_loader = DataServer(self.target_valid_data, self.vocab, self.opt)

                while True:
                    # Draw mini-batches to be used for the generator and discriminator validation steps
                    try:
                        source_labels, source_enc_inputs, source_dec_inputs = next(source_valid_loader)
                        target_labels, target_enc_inputs, target_dec_inputs = next(target_valid_loader)
                    except StopIteration:
                        break

                    # Perform joint validation
                    # Perform a single validation step
                    gen_valid_loss, disc_valid_loss, id_reduction_score, partial_losses = self.joint_valid_step(
                        source_labels, source_enc_inputs, source_dec_inputs,
                        target_labels, target_enc_inputs, target_dec_inputs)
                    # Update tracked generator values
                    gen_valid_losses.append(gen_valid_loss)
                    gen_adv_losses.append(partial_losses[0])
                    gen_rec_losses.append(partial_losses[1])
                    # Update tracked discriminator values
                    disc_valid_losses.append(disc_valid_loss)
                    # Update ID reduction values observed during training
                    id_reduction_scores.append(id_reduction_score)
                    # Update global step variables
                    self.gen_valid_global_step += 1
                    self.disc_valid_global_step += 1

                    # Calculate validation statistics for the reporting interval
                    if self.total_valid_global_step % self.opt.report_freq == 0 and self.total_valid_global_step != 0:
                        logging.info('[VALIDATION] Epoch {:d} | Global GAN step: {:d}'.format(
                            e, self.total_valid_global_step))

                        # Generator statistics
                        if self.gen_iterations > 0:
                            gen_valid_loss_avg = sum(gen_valid_losses[-self.opt.report_freq:]) / self.opt.report_freq
                            id_reduction_score_avg = sum(
                                id_reduction_scores[-self.opt.report_freq:]) / self.opt.report_freq
                            logging.info('[GEN] Global step: {:d} | Loss mean: {:.4f}'.format(
                                self.gen_valid_global_step, gen_valid_loss_avg))
                            logging.info('[GEN] ID reduction mean: {:.4f}'.format(id_reduction_score_avg))

                        # Discriminator statistics
                        if self.disc_iterations > 0:
                            disc_valid_loss_avg = sum(disc_valid_losses[-self.opt.report_freq:]) / self.opt.report_freq
                            logging.info('[DISC] Global step: {:d} | Loss mean: {:.4f}'.format(
                                self.disc_valid_global_step, disc_valid_loss_avg))

                    # Update GAN global step variable
                    self.total_valid_global_step += 1

                # Calculate validation statistics for the full validation epoch
                logging.info('[VALIDATION] EPOCH {:d} CONCLUDED'.format(e))
                epoch_valid_losses = list()

                # Generator statistics
                if self.gen_iterations > 0:
                    gen_epoch_valid_loss_avg = sum(gen_valid_losses) / len(gen_valid_losses)
                    gen_epoch_id_reduction_avg = sum(id_reduction_scores) / len(id_reduction_scores)
                    epoch_id_reduction = gen_epoch_id_reduction_avg
                    epoch_valid_losses.append(gen_epoch_valid_loss_avg)
                    logging.info('[GEN] EPOCH LOSS MEAN: {:.4f}'.format(gen_epoch_valid_loss_avg))
                    logging.info('[GEN] EPOCH ID REDUCTION MEAN: {:.4f}'.format(epoch_id_reduction))

                # Discriminator statistics
                if self.disc_iterations > 0:
                    disc_epoch_valid_loss_avg = sum(disc_valid_losses) / len(disc_valid_losses)
                    epoch_valid_losses.append(disc_epoch_valid_loss_avg)
                    logging.info('[DISC] EPOCH LOSS MEAN: {:.4f}'.format(disc_epoch_train_loss_avg))

                # Pickle tracked epoch-wise validation values for subsequent access
                self.valid_pickle_dict['gen_valid_losses'].append(np.mean(gen_valid_losses))
                self.valid_pickle_dict['id_reduction_scores'].append(np.mean(id_reduction_scores))
                self.valid_pickle_dict['disc_valid_losses'].append(np.mean(disc_valid_losses))
                self.valid_pickle_dict['gen_adv_losses'].append(np.mean(gen_adv_losses))
                self.valid_pickle_dict['gen_rec_losses'].append(np.mean(gen_rec_losses))
                with open(self.valid_pickle_archive, 'wb') as in_pickle:
                    pickle.dump(self.valid_pickle_dict, in_pickle)

                # Sample generator's output - with corresponding surprisal and ID reduction scores - after each
                # validation epoch, to track model performance
                logging.info('=' * 10)
                if self.interface is not None:
                    assert (self.test_opt is not None), \
                        'Sample generation requires test options to have been specified.'
                    # Draw samples and greedily reconstruct them
                    train_samples = np.random.choice(self.source_train_data, self.test_opt.num_samples).tolist()
                    valid_samples = np.random.choice(self.source_valid_data, self.test_opt.num_samples).tolist()
                    train_samples_loader = DataServer(train_samples, self.vocab, self.test_opt)
                    valid_samples_loader = DataServer(valid_samples, self.vocab, self.test_opt)
                    train_samples_read = 0
                    valid_samples_read = 0
                    # Training set sampling
                    logging.info('Training samples decoding:')
                    for i, sample_data in enumerate(train_samples_loader):
                        enc_labels, enc_input, dec_input = sample_data
                        generated = self.interface.greedy_generation(enc_labels, enc_input, dec_input)
                        for j in range(self.test_opt.batch_size):
                            logging.info('Encoded: {:s}\nEncoded ID: {:.4f}\nDecoded: {:s}\nDecoded ID: {:.4f}\n'
                                         'ID reduction: {:.4f}'
                                         .format(train_samples[train_samples_read + j], generated[j][2],
                                                 generated[j][0], generated[j][1], generated[j][3]))
                        train_samples_read += self.test_opt.batch_size
                    logging.info('-' * 10)
                    # Validation set sampling
                    logging.info('Validation samples decoding:')
                    for i, sample_data in enumerate(valid_samples_loader):
                        enc_labels, enc_input, dec_input = sample_data
                        generated = self.interface.greedy_generation(enc_labels, enc_input, dec_input)
                        for j in range(self.test_opt.batch_size):
                            logging.info('Encoded: {:s}\nEncoded ID: {:.4f}\nDecoded: {:s}\nDecoded ID: {:.4f}\n'
                                         'ID reduction: {:.4f}'
                                         .format(valid_samples[valid_samples_read + j], generated[j][2],
                                                 generated[j][0], generated[j][1], generated[j][3]))
                        valid_samples_read += self.test_opt.batch_size
                logging.info('=' * 10)

                # Keep track of validation losses to identify best-performing epoch
                # Mean epoch loss value is used to estimate IDGAN's best validation epoch performance
                epoch_train_loss = np.mean(epoch_train_losses)
                epoch_valid_loss = np.mean(epoch_valid_losses)

                # Maintain a best overall validation checkpoint
                if epoch_valid_loss < self.all_validation_best:
                    self.all_validation_best = epoch_valid_loss
                    self.all_training_best = epoch_train_loss
                    save_model(self.session, self.model, self.model_saver, self.opt.save_dir, 'validation_best')
                    # Report epoch results upon saving learned parameters
                    print('\nTotal validation best checkpoint saved!\n'
                          'Total validation loss: {:.4f} | Total training loss: {:.4f}\n'
                          'Individual training losses (gen | disc): {:s}\n'
                          'Individual validation losses (gen | disc): {:s}\n'.
                          format(self.all_validation_best, self.all_training_best,
                                 ' | '.join('{:.4f}'.format(loss) for loss in epoch_train_losses),
                                 ' | '.join('{:.4f}'.format(loss) for loss in epoch_valid_losses)))
                    self.stagnant_epochs = 0

                # Maintain a best validation epoch ID-reduction checkpoint
                if epoch_id_reduction > self.id_reduction_best:
                    self.id_reduction_best = epoch_id_reduction
                    self.id_validation_best = epoch_valid_loss
                    self.id_training_best = epoch_train_loss
                    self.best_epoch = e
                    save_model(self.session, self.model, self.model_saver, self.opt.save_dir, 'id_best')
                    # Report epoch results upon saving learned parameters
                    print('\nID reduction best checkpoint saved!\n'
                          'Total ID reduction score: {:.4f}\n'
                          'Total validation loss: {:.4f} | Total training loss: {:.4f}\n'
                          'Individual training losses (gen | disc): {:s}\n'
                          'Individual validation losses (gen | disc): {:s}\n'.
                          format(self.id_reduction_best, self.id_validation_best, self.id_training_best,
                                 ' | '.join('{:.4f}'.format(loss) for loss in epoch_train_losses),
                                 ' | '.join('{:.4f}'.format(loss) for loss in epoch_valid_losses)))
                    self.stagnant_epochs = 0

                # If overall validation or ID-reduction performance did not improve,
                # increment number of 'stagnant' epochs
                if epoch_valid_loss >= self.all_validation_best and epoch_id_reduction <= self.id_reduction_best:
                    self.stagnant_epochs += 1

                # Optionally trigger early stopping after the specified number of validation epochs during which model
                # performance did not improve
                if self.opt.enable_early_stopping and self.stagnant_epochs >= self.opt.patience:
                    logging.info('Training terminated early after {:d} stagnant epochs | Final epoch: {:d}.'
                                 .format(self.stagnant_epochs, e))
                    self.final_epoch = e
                    self.stopped_early = True
                    break

                # Reduce the training rate by a set amount after the specified number of 'stagnant' validation epochs
                if self.stagnant_epochs % \
                        self.opt.annealing_step == 0 and self.stagnant_epochs >= self.opt.annealing_step:
                    old_gen_lr = self.current_gen_lr
                    old_disc_lr = self.current_disc_lr
                    # Generator and discriminator LRs may be annealed independently
                    self.current_gen_lr *= self.opt.gen_annealing_factor
                    self.current_disc_lr *= self.opt.disc_annealing_factor
                    logging.info('Generator LR reduced from {:.8f} to {:.8f}\n'
                                 'Discriminator LR reduced from {:.8f} to {:.8f}\n'
                                 'after {:d} stagnant epochs'.format(old_gen_lr, self.current_gen_lr, old_disc_lr,
                                                                     self.current_disc_lr, self.stagnant_epochs))

                # Optionally switch between adversarial and reconstruction objectives after each validation epoch
                if self.opt.multi_task == 'dynamic':
                    _switch_task(gen_adv_losses)

                # Optionally save model parameters periodically throughout the training process
                if self.opt.save_freq is not None:
                    if e % self.opt.save_freq == 0 and e != 0:
                        save_model(self.session, self.model, self.model_saver, self.opt.save_dir, e)

        time_total = time.time() - self.start_time
        minutes = int(time_total // 60)
        seconds = int(time_total % 60)
        # Save the final set of learned parameters after the conclusion of the training loop
        save_model(self.session, self.model, self.model_saver, self.opt.save_dir, 'gan_final')

        # Final report
        if self.stopped_early:
            logging.info('{:s} training terminated after {:d} epochs ({:d} minutes and {:.2f} seconds).\n'
                         'Best ID reduction epoch: {:d} | Best translation ID score: {:.4f}\n'
                         'Training loss at best epoch: {:.4f} | Validation loss at best epoch: {:.4f}\n'
                         .format(self.model.name, self.final_epoch, minutes, seconds, self.best_epoch,
                                 self.id_reduction_best, self.id_validation_best, self.id_training_best))
        else:
            logging.info('{:s} training finished after {:d} epochs ({:d} minutes and {:.2f} seconds).\n'
                         'Best ID reduction epoch: {:d} | Best translation ID score: {:.4f}\n'
                         'Training loss at best epoch: {:.4f} | Validation loss at best epoch: {:.4f}\n'
                         .format(self.model.name, self.opt.num_epochs, minutes, seconds, self.best_epoch,
                                 self.id_reduction_best, self.id_validation_best, self.id_training_best))

    # ============================= #
    # TRAINING AND VALIDATION STEPS #
    # ============================= #

    # =========== #
    # JOINT STEPS #
    # =========== #

    def joint_train_step(self, source_labels, source_enc_inputs, source_dec_inputs,
                         target_labels, target_enc_inputs, target_dec_inputs):
        """ Performs a single joint training step for the IDGAN generator and discriminator. """
        # feed_dict is built incrementally for easier debugging and ablation evaluation
        gen_feed = [(self.model.source_labels, source_labels),
                    (self.model.source_enc_inputs, source_enc_inputs),
                    (self.model.source_dec_inputs, source_dec_inputs),
                    (self.model.gen.enc.static_keep_prob, self.opt.enc_static_keep_prob),
                    (self.model.gen.enc.rnn_keep_prob, self.opt.enc_rnn_keep_prob),
                    (self.model.gen.dec.static_keep_prob, self.opt.dec_static_keep_prob),
                    (self.model.gen.dec.rnn_keep_prob, self.opt.dec_rnn_keep_prob),
                    (self.model.gen.dec.sampling_bias, self.sampling_bias),
                    (self.model.gen_lr, self.current_gen_lr)]

        truth_feed = [(self.model.target_labels, target_labels),
                      (self.model.target_enc_inputs, target_enc_inputs),
                      (self.model.target_dec_inputs, target_dec_inputs),
                      (self.model.truth.enc.static_keep_prob, 1.0),
                      (self.model.truth.enc.rnn_keep_prob, 1.0),
                      (self.model.truth.dec.static_keep_prob, 1.0),
                      (self.model.truth.dec.rnn_keep_prob, 1.0),
                      (self.model.truth.dec.sampling_bias, 1.0)]

        disc_feed = [(self.model.disc.static_keep_prob, self.opt.disc_static_keep_prob),
                     (self.model.disc_lr, self.current_disc_lr)]

        lm_feed = [(self.model.lm.static_keep_prob, 1.0),
                   (self.model.lm.rnn_keep_prob, 1.0)]

        hyper_feed = [(self.model.adv_lambda, self.opt.adv_lambda),
                      (self.model.id_lambda, self.opt.id_lambda),
                      (self.model.rec_lambda, self.opt.rec_lambda)]

        gan_only = gen_feed + truth_feed + disc_feed + hyper_feed
        gan_full = gan_only + lm_feed
        feed_dict = {tpl[0]: tpl[1] for tpl in gan_full}

        # OPs called within the IDGAN graph
        gen_ops = [self.model.gen_grad_norm, self.model.gen_loss, self.model.gen_train_op]
        disc_ops = [self.model.disc_grad_norm, self.model.disc_loss, self.model.disc_train_op]
        info_ops = [self.model.id_reduction, self.model.partial_gen_losses]
        ops = gen_ops + disc_ops + info_ops
        # Extend OP list with summary OPs to be called periodically throughout the training
        ops_plus_gen_summaries = ops + [self.model.gen_summaries]
        ops_plus_disc_summaries = ops + [self.model.disc_summaries]
        ops_plus_all_summaries = ops_plus_gen_summaries + [self.model.disc_summaries]
        # Declare summary writing conditions
        summarize_gen = self.gen_train_global_step % self.opt.summary_freq == 0 and self.gen_train_global_step != 0
        summarize_disc = self.disc_train_global_step % self.opt.summary_freq == 0 and self.disc_train_global_step != 0

        # Call OPs and write collected step-wise summaries
        if summarize_gen and summarize_disc:
            fetches = self.session.run(ops_plus_all_summaries, feed_dict=feed_dict)
            self.gen_train_writer.add_summary(summary=fetches[-2], global_step=self.total_train_global_step)
            self.disc_train_writer.add_summary(summary=fetches[-1], global_step=self.total_train_global_step)
            fetches = fetches[: -2]
        elif summarize_gen and not summarize_disc:
            fetches = self.session.run(ops_plus_gen_summaries, feed_dict=feed_dict)
            self.gen_train_writer.add_summary(summary=fetches[-1], global_step=self.total_train_global_step)
            fetches = fetches[: -1]
        elif not summarize_gen and summarize_disc:
            fetches = self.session.run(ops_plus_disc_summaries, feed_dict=feed_dict)
            self.disc_train_writer.add_summary(summary=fetches[-1], global_step=self.total_train_global_step)
            fetches = fetches[: -1]
        else:
            # Call OPs only
            fetches = self.session.run(ops, feed_dict=feed_dict)

        if self.verbose and self.total_train_global_step % (self.opt.report_freq // 2) == 0:
            # Track partial objectives throughout the training process if reporting mode is set to 'verbose'
            logging.info('==== Partial objectives ====')
            logging.info('[GEN] Adv. loss: {: .6f} | Rec. loss: {: .6f}'
                         .format(fetches[7][0], fetches[7][1]))
            logging.info('[GEN] Total loss: {: .6f} | ID reduction: {: .6f}'
                         .format(fetches[1], fetches[6]))
            logging.info('[DISC] Adv. loss: {: .6f}'.format(fetches[4]))
            logging.info('============================')

        # Unpack fetched values
        gen_grad_norm = fetches[0]
        gen_train_loss = fetches[1]
        disc_grad_norm = fetches[3]
        disc_train_loss = fetches[4]
        id_reduction = fetches[6]
        partial_losses = fetches[7]
        return gen_grad_norm, gen_train_loss, disc_grad_norm, disc_train_loss, id_reduction, partial_losses

    def joint_valid_step(self, source_labels, source_enc_inputs, source_dec_inputs,
                         target_labels, target_enc_inputs, target_dec_inputs):
        """ Performs a single joint validation step for the IDGAN generator and discriminator. """
        # feed_dict is built incrementally for easier debugging and ablation evaluation
        gen_feed = [(self.model.source_labels, source_labels),
                    (self.model.source_enc_inputs, source_enc_inputs),
                    (self.model.source_dec_inputs, source_dec_inputs),
                    (self.model.gen.enc.static_keep_prob, self.opt.enc_static_keep_prob),
                    (self.model.gen.enc.rnn_keep_prob, self.opt.enc_rnn_keep_prob),
                    (self.model.gen.dec.static_keep_prob, self.opt.dec_static_keep_prob),
                    (self.model.gen.dec.rnn_keep_prob, self.opt.dec_rnn_keep_prob),
                    (self.model.gen.dec.sampling_bias, self.sampling_bias)]

        truth_feed = [(self.model.target_labels, target_labels),
                      (self.model.target_enc_inputs, target_enc_inputs),
                      (self.model.target_dec_inputs, target_dec_inputs),
                      (self.model.truth.enc.static_keep_prob, 1.0),
                      (self.model.truth.enc.rnn_keep_prob, 1.0),
                      (self.model.truth.dec.static_keep_prob, 1.0),
                      (self.model.truth.dec.rnn_keep_prob, 1.0),
                      (self.model.truth.dec.sampling_bias, 1.0)]

        disc_feed = [(self.model.disc.static_keep_prob, 1.0)]

        lm_feed = [(self.model.lm.static_keep_prob, 1.0),
                   (self.model.lm.rnn_keep_prob, 1.0)]

        hyper_feed = [(self.model.adv_lambda, self.opt.adv_lambda),
                      (self.model.id_lambda, self.opt.id_lambda),
                      (self.model.rec_lambda, self.opt.rec_lambda)]

        gan_only = gen_feed + truth_feed + disc_feed + hyper_feed
        gan_full = gan_only + lm_feed
        feed_dict = {tpl[0]: tpl[1] for tpl in gan_full}

        # OPs called within the IDGAN graph
        gen_ops = [self.model.gen_loss]
        disc_ops = [self.model.disc_loss]
        info_ops = [self.model.id_reduction, self.model.partial_gen_losses]
        ops = gen_ops + disc_ops + info_ops
        # Extend OP list with summary OPs to be called periodically throughout the validation process
        ops_plus_gen_summaries = ops + [self.model.gen_summaries]
        ops_plus_disc_summaries = ops + [self.model.disc_summaries]
        ops_plus_all_summaries = ops_plus_gen_summaries + [self.model.disc_summaries]

        # Declare summary writing conditions
        summarize_gen = \
            self.gen_valid_global_step % (self.opt.summary_freq // 3) == 0 and self.gen_valid_global_step != 0
        summarize_disc = \
            self.disc_valid_global_step % (self.opt.summary_freq // 3) == 0 and self.disc_valid_global_step != 0

        # Call OPs and write collected step-wise summaries
        if summarize_gen and summarize_disc:
            fetches = self.session.run(ops_plus_all_summaries, feed_dict=feed_dict)
            self.gen_valid_writer.add_summary(summary=fetches[-2], global_step=self.total_valid_global_step)
            self.disc_valid_writer.add_summary(summary=fetches[-1], global_step=self.total_valid_global_step)
            fetches = fetches[: -2]
        elif summarize_gen and not summarize_disc:
            fetches = self.session.run(ops_plus_gen_summaries, feed_dict=feed_dict)
            self.gen_valid_writer.add_summary(summary=fetches[-1], global_step=self.total_valid_global_step)
            fetches = fetches[: -1]
        elif not summarize_gen and summarize_disc:
            fetches = self.session.run(ops_plus_disc_summaries, feed_dict=feed_dict)
            self.disc_valid_writer.add_summary(summary=fetches[-1], global_step=self.total_valid_global_step)
            fetches = fetches[: -1]
        else:
            # Call OPs only
            fetches = self.session.run(ops, feed_dict=feed_dict)

        # Unpack fetched values
        gen_valid_loss = fetches[0]
        disc_valid_loss = fetches[1]
        id_reduction_score = fetches[2]
        partial_losses = fetches[3]
        return gen_valid_loss, disc_valid_loss, id_reduction_score, partial_losses

    # ============== #
    # GENERATOR STEP #
    # ============== #

    def gen_train_step(self, source_labels, source_enc_inputs, source_dec_inputs,
                       target_labels, target_enc_inputs, target_dec_inputs):
        """ Performs a single training step for the IDGAN generator only. """
        # feed_dict is built incrementally for easier debugging and ablation evaluation
        gen_feed = [(self.model.source_labels, source_labels),
                    (self.model.source_enc_inputs, source_enc_inputs),
                    (self.model.source_dec_inputs, source_dec_inputs),
                    (self.model.gen.enc.static_keep_prob, self.opt.enc_static_keep_prob),
                    (self.model.gen.enc.rnn_keep_prob, self.opt.enc_rnn_keep_prob),
                    (self.model.gen.dec.static_keep_prob, self.opt.dec_static_keep_prob),
                    (self.model.gen.dec.rnn_keep_prob, self.opt.dec_rnn_keep_prob),
                    (self.model.gen.dec.sampling_bias, self.sampling_bias),
                    (self.model.gen_lr, self.current_gen_lr)]

        truth_feed = [(self.model.target_labels, target_labels),
                      (self.model.target_enc_inputs, target_enc_inputs),
                      (self.model.target_dec_inputs, target_dec_inputs),
                      (self.model.truth.enc.static_keep_prob, 1.0),
                      (self.model.truth.enc.rnn_keep_prob, 1.0),
                      (self.model.truth.dec.static_keep_prob, 1.0),
                      (self.model.truth.dec.rnn_keep_prob, 1.0),
                      (self.model.truth.dec.sampling_bias, 1.0)]

        disc_feed = [(self.model.disc.static_keep_prob, self.opt.disc_static_keep_prob)]

        lm_feed = [(self.model.lm.static_keep_prob, 1.0),
                   (self.model.lm.rnn_keep_prob, 1.0)]

        hyper_feed = [(self.model.adv_lambda, self.opt.adv_lambda),
                      (self.model.id_lambda, self.opt.id_lambda),
                      (self.model.rec_lambda, self.opt.rec_lambda)]

        gan_only = gen_feed + truth_feed + disc_feed + hyper_feed
        gan_full = gan_only + lm_feed
        feed_dict = {tpl[0]: tpl[1] for tpl in gan_full}

        # OPs called within the IDGAN graph
        ops = [self.model.gen_grad_norm, self.model.gen_loss, self.model.gen_train_op]
        info_ops = [self.model.id_reduction, self.model.partial_gen_losses]
        ops += info_ops
        # Extend OP list with summary OPs
        ops_plus_summaries = ops + [self.model.gen_summaries]

        # Call OPs and write collected step-wise summaries
        if self.gen_train_global_step % self.opt.summary_freq == 0 and self.gen_train_global_step != 0:
            fetches = self.session.run(ops_plus_summaries, feed_dict=feed_dict)
            self.gen_train_writer.add_summary(summary=fetches[-1], global_step=self.total_train_global_step)
            fetches = fetches[: -1]
        else:
            # Call OPs only
            fetches = self.session.run(ops, feed_dict=feed_dict)

        if self.verbose and self.gen_train_global_step % (self.opt.report_freq // 2) == 0:
            # Track partial objectives throughout the training process if reporting mode is set to 'verbose'
            logging.info('==== Partial objectives ====')
            logging.info('[GEN] Adv. loss: {: .6f} | Rec. loss: {: .6f}'
                         .format(fetches[4][0], fetches[4][1]))
            logging.info('[GEN] Total loss: {: .6f} | ID reduction: {: .6f}'
                         .format(fetches[1], fetches[3]))
            logging.info('============================')

        # Unpack fetched values
        batch_grad_norm = fetches[0]
        train_batch_loss = fetches[1]
        id_reduction = fetches[3]
        partial_losses = fetches[4]
        return batch_grad_norm, train_batch_loss, id_reduction, partial_losses

    # ================== #
    # DISCRIMINATOR STEP #
    # ================== #

    def disc_train_step(self, source_enc_inputs, target_enc_inputs):
        """ Performs a single training step for the IDGAN generator only. """
        # feed_dict is built incrementally for easier debugging and ablation evaluation
        gen_feed = [(self.model.source_enc_inputs, source_enc_inputs),
                    (self.model.gen.enc.static_keep_prob, self.opt.enc_static_keep_prob),
                    (self.model.gen.enc.rnn_keep_prob, self.opt.enc_rnn_keep_prob),
                    (self.model.gen.dec.static_keep_prob, self.opt.dec_static_keep_prob),
                    (self.model.gen.dec.rnn_keep_prob, self.opt.dec_rnn_keep_prob),
                    (self.model.gen.dec.sampling_bias, self.sampling_bias)]

        truth_feed = [(self.model.target_enc_inputs, target_enc_inputs),
                      (self.model.truth.enc.static_keep_prob, 1.0),
                      (self.model.truth.enc.rnn_keep_prob, 1.0),
                      (self.model.truth.dec.static_keep_prob, 1.0),
                      (self.model.truth.dec.rnn_keep_prob, 1.0),
                      (self.model.truth.dec.sampling_bias, 1.0)]

        disc_feed = [(self.model.disc.static_keep_prob, self.opt.disc_static_keep_prob),
                     (self.model.disc_lr, self.current_disc_lr)]

        gan_only = gen_feed + truth_feed + disc_feed
        feed_dict = {tpl[0]: tpl[1] for tpl in gan_only}

        # OPs called within the IDGAN graph
        ops = [self.model.disc_grad_norm, self.model.disc_loss, self.model.disc_train_op]
        # Extend OP list with summary OPs
        ops_plus_summaries = ops + [self.model.disc_summaries]

        # Call OPs and write collected step-wise summaries
        if self.disc_train_global_step % self.opt.summary_freq == 0 and self.disc_train_global_step != 0:
            fetches = self.session.run(ops_plus_summaries, feed_dict=feed_dict)
            self.disc_train_writer.add_summary(summary=fetches[-1], global_step=self.total_train_global_step)
            fetches = fetches[: -1]
        else:
            # Call OPs only
            fetches = self.session.run(ops, feed_dict=feed_dict)

        if self.verbose and self.disc_train_global_step % (self.opt.report_freq // 2) == 0:
            # Track partial objectives throughout the training process if reporting mode is set to 'verbose'
            logging.info('==== Partial objectives ====')
            logging.info('[DISC] Adv loss: {: .6f}'.format(fetches[1]))
            logging.info('============================')

        # Unpack fetched values
        batch_grad_norms = fetches[0]
        train_batch_losses = fetches[1]
        return batch_grad_norms, train_batch_losses
